{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f2caf7a-d054-46f8-b506-0201ac32bc7e",
   "metadata": {},
   "source": [
    "# COVID-19 Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a0be8-1ef7-417b-88d9-f7cfa472e2a8",
   "metadata": {},
   "source": [
    "<h3>Problem Statement:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5175feb-7a4f-4680-86e4-616a44f4ae65",
   "metadata": {},
   "source": [
    "- To comprehensive analysis and visualization of COVID-19 data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8710301-3404-4289-b0e0-834144430be2",
   "metadata": {},
   "source": [
    "<h3>Task Performed</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848429ac-6a52-4ead-9531-d5c169ae9711",
   "metadata": {},
   "source": [
    "<h4>Step 1: Data Collection and Cleaning</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc6b39-5337-4820-80b1-b7c578c68708",
   "metadata": {},
   "source": [
    "In the first step, I imported pandas library for data collection and cleaning. During the process, I read the csv file of the COVID-19 provided by WHO. The csv file name is 'WHO-COVID-19-global-data.csv'. After that i analyzed data using differrent functions like head, info, describe, null and soon to know about the data shape, types, descriptive summary of all variables , their null values, duplicate values. In the dataset, I found missing values in both categorical and numerical variables. To handle missing values, I inserted median values for numerical variables while mode for the categorical variables. I even detected the outliers and normalized the columns by removing outliers. Then the cleaned dataset was saved into csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acdd03-8ae5-404d-b633-bf7d68dbb185",
   "metadata": {},
   "source": [
    "<h4>Step 2: Exploratory Data Analysis</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcde09e-8c67-4d78-882a-8d47812b3392",
   "metadata": {},
   "source": [
    "In the second phase, I read the cleaned dataset saved in the csv file in step 1. Then, I performed statistical analysis like mean, median, standard deviation, range to analyze about the dataset.After performing statistical analysis, I visualized the dataset using different figures. First of all, I used bar chart to visualize the average of new cases and deaths for their respective WHO_regions.In the respective visualization, I found the average count of new cases were significantly higher than average of new deaths. Secondly, I used histogram for visualizing the new cases and new deaths. Since, the dataset is relatively large, I choosed HeatMap for showing the correlation between country with new cases and new_deaths. In both visualization, I found positive coorelation between two variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0ddcb-69a2-49f9-98fd-36500c6380d0",
   "metadata": {},
   "source": [
    "Libraries used for visualization:\n",
    "1. Numpy\n",
    "2. Pandas\n",
    "3. Matplotlib.pyplot\n",
    "4. seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51962c67-342c-48a0-aec4-2d7927dd2d1d",
   "metadata": {},
   "source": [
    "<h4>Step 3:Interactive Dashboard Creation</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f6498-789d-4e40-8a74-343ec9d9182a",
   "metadata": {},
   "source": [
    "For this I used Tableau Public. I uploaded the cleaned csv file into Tableu Public. Then, I started visualizing the different columns and rows in different sheets using all the tools and options available. Finally, I merged them together in a dashboard for the final visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9850461-5a99-43fc-bbd3-1ade48786305",
   "metadata": {},
   "source": [
    "<h3> Challenges Faced </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5c8cb-0db5-4d38-a915-a1f986563ed4",
   "metadata": {},
   "source": [
    "1. The first challenge was to handle missing values. Choosing the best imputation technique was challenging for me because there were lot of missing values in each column.\n",
    "2. Selecting the most effective visualization was another challenge. Since, the datasets were large and there were outliers present in the dataset, so it was challenging for me to find approriate visualizations that convey the meaningful interpretations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
